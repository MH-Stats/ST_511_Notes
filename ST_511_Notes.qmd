---
title: "ST 511 Notes"
format:
  html: 
    toc: true
editor: visual
editor_options:
  chunk_output_type: inline
---

# #Week 1

## Git/Github

### Syntax for Git

Replace file path with an empty folder path one on your end and change
the url to the one you want to copy:

-   `git clone https://github.com/MH-Stats/Math_Notes.git "C:\Users\mheinen\Documents\Repos\SSH\_Test"`

How to pull files from GitHub repo:

-   `git pull origin main`

How to commit and upload changes using gitbash:

-   change lib in gitbash `cd C:/Users/mheinen/Documents/Repos/SSH_Test`

Check untracked files:

-   `git status`

Stage specific file:

-   `git add filename`

Stage all files:

-   `git add .`

Commit changes: - `git commit -m "Add your message here"`

Push changes to the repo (change main to branch if using a different
one): - `git push origin main`

# Week 4

## Random Variable

Random variables (RV) are ways to map random or stochastic process to
numbers, which is a mathematical object defined as a family of random
variables in a probability space, with the most common index fro the
family being time. They are the building blocks of probability
distributions, and a probability distribution describes the set of all
possible values a RV can take and the probability of each value
occurring.

-   Can be discrete or continuous

-   Normally represented by uppercase letters like $X$

-   Useful when you know the exact population distribution, as you can
    use it to calculate probabilities, as an example you know the
    probability of rolling a 1 through 6 on a dice.

## Probability and Sampling Distribution

The probability distribution of a population directly influences the
sampling distribution of a statistic drawn from that population. A
sampling distribution is essentially the probability distribution of a
statistic from all possible samples of a given size.

The spread of the sampling distribution is,

$$\frac{\sigma}{\sqrt{n}}$$

Since we normally only get a single sample, we assume that,

$$\bar{x} \approx N(\mu,\frac{\sigma}{\sqrt{n}})$$

-   We estimate $\mu$ with $\bar{x}$ and $\sigma$ with $s$

### Normality

If the probability distribution is normal, the sampling distribution
will also be normal.

### The Central Limit Theorem

For large independent samples (n\>30), regardless of of what the
population distribution looks like, the sampling distribution of the
sample mean will be normally distributed with mean $\mu$ and standard
error of $\frac{\sigma}{\sqrt{n}}$

Z and t-test assume the sampling distribution is normally distributed.
This is also why:

-   $\bar{x}$ is unbiased estimator for $\mu$

### Notation

To write the mean and standard deviation in a distribution you can write
it as,

$$X \sim N(\mu, \sigma)$$

When writing out the probability you can write it as,

$$P(X>x) \qquad \text{where } X \text{ is the random variable, } x \text{ is the value, and > is greater than (can be >, <, =, etc.)}$$

## Finding Average Word Count in R

```{r}
library(stringr) #Used for str_split

#Creating a character vector from the address 
address <- "Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.

Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this.

But, in a larger sense, we can not dedicate -- we can not consecrate -- we can not hallow -- this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us -- that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion -- that we here highly resolve that these dead shall not have died in vain -- that this nation, under God, shall have a new birth of freedom -- and that government of the people, by the people, for the people, shall not perish from the earth."

address_count <- str_split(address, "\\W+") #Splits up the text by " " and removes white space and other non-letter chars from address

address_clean <- address_count[[1]][-273] #Removes last element which was null aka ""

address_clean[1:20] #Using indexing to show a snippet of what the character vector now looks like
```

```{r}
avg_length <- mean(nchar(address_clean)) #nchar is a built in R function to tell you character length

#Paste allows you to put multiple inputs into a function like print()
print(paste("The average word length in the Gettysburg Address is", avg_length))
```

```{r}
set.seed(24) #Setting seed

address_sample <- sample(address_clean, 10) #Sampling 10 words from the cleaned address vector

avg_sample_length <- mean(nchar(address_sample))

print(paste("The average word length in the sample of the Gettysburg Address is", avg_sample_length))
```

# Week 5 to 6

## Hypothesis Testing

### Assumptions

Must check that the data has two thing:

-   Independence

-   Normality

    -   Data must be "normal" meaning the sample size n must satisfy two
        conditions:
        -   $n * \pi_0\geq10$
        -   $n * (1-\pi_0)\geq10$

### Z-distribution

Z-score is a ratio of how the sample proportion differs from the
hypothesized proportion ($p_0$) as compared to the expected variability
of the $\hat{p}$ (sample proportion) values.

$$Z = \frac{\hat{p}-p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}$$

-   The standard error, which is the the standard deviation of the
    sampling distribution comes from the above formula,

$$SE=\sqrt{\frac{p_0(1-p_0)}{n}}$$

When the null hypothesis is true and the conditions are met, Z has a
standard normal distribution.

### Notation

When writing null and alternative hypothesis follow the following syntax
based on if your data is quantitative or categorical:

Quantitative

-   Your hypothesis are about a population mean

-   Use $\mu$, as an example say your testing that the average height of
    a population is 64 inches, but you believe the true average height
    is greater than 64

$$
\begin{align*}
H_0 &: \mu = 64 \\
H_a &: \mu > 64
\end{align*}
$$

Categorical

-   Use $\pi$ when your dealing with categorical data, as you are
    testing the hypothesis about a population proportion. As an example
    say you want to test if 25% of people prefer sleeping with their
    socks on.

$$
\begin{align*}
H_0 &: \pi = .25 \\
H_a &: \pi \ne .25
\end{align*}
$$

## Confidence Intervals

The goal of a confidence interval is to create a sampling distribution
around our statistic, and use the standard error (sampling variability)
to provide a range of values to estimate our population parameter.

A confidence interval is a derived from the successes and failures of
our random sample, while hypothesis testing is the successes and
failures under the assumption of the null hypothesis.

### Notation

Formula:

$$\hat{p}\pm MOE$$

Margin of Error (MOE):

$$z^* * \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$$

-   The square root in the formula is equal to $SE(\hat{p})$

### Example

We want to estimate the number of NC State students that eat ice cream.
Let’s assume that 100 NC State students were randomly sampled, and it
turned out that $\hat{p}=0.37$. This is our best guess for π, which
nobody thinks is actually correct.

We need to check for a couple things and note our variables of interest:

-   Independence

-   $\hat{p}=0.37$

-   $n=100$

-   Success/Failure:

$$SE(\hat{p})=\sqrt{\frac{0.37(1-0.37)}{100}}=0.0482$$

Now we can calculate a 95% confidence interval:

$$0.37 \pm 1.96 * 0.0428=(0.286, 0.454)$$

Two ways to state in words:

1.  We are 95% confident $\pi$ is within (0.286, 0.454).

2.  We are 95% confident that the true proportion of NC State students
    who eat Howling Cow ice cream at dinner is between 0.286 and 0.454.

## Difference In Proportions Test

Also know as a two-proportion z-test. It is a z-test used to determine
whether the difference between the proportions of two groups, coming
from a binomial distribution is statistical significant.

### Example

A pharmaceutical company is conducting a clinical trial to test the
effectiveness of a new drug for a common illness. They randomly assign
participants to one of two groups

Group 1 (New Drug): Out of 200 patients, 160 recovered from the illness.

Group 2 (Placebo): Out of 180 patients, 126 recovered from the illness.

Perform a hypothesis test to determine if the proportion of patients who
recovered is significantly different for the group that received the new
drug

#### Notation

$H_o:\pi_n-\pi_p=0$

$H_a:\pi_n-\pi_p>0$

$\hat{p}_n - \hat{p}_p=.1$

#### Assumptions

-   Independence (observation level, not variables)

-   Success-failure (sample size)

![](Images\pool.png)

-   You need to check both $p_1$ & $p_2$ by using the pooled proportion
    multiplied by the sample size n for each sample.
    -   is $p_{pool} * n_1>10$
    -   is $(1-p_{pool})*n_1>10$
    -   is $p_{pool}*n_2>10$
    -   is $(1-p_{pool})*n_2>10$

#### Z-test

![](Images\zpool.png)

$$
Z=\frac{.1-0}{\sqrt{.744*.226(\frac{1}{200}+\frac{1}{180})}}=2.327
$$

#### Conclusion

Because or p-value is \< α, we reject the null hypothesis, and have
strong evidence to conclude that the true proportion of patients who
recovered from the illness taking the new drug is larger than those who
took the placebo.

### Confidence Interval

#### Assumptions

-   Independence

-   Success-failure

    -   $\hat{p}_n*n_1>10$
        -   $.8*200>10$
    -   $(1-\hat{p}_n)*n_1>10$
        -   $.2*200>10$
    -   $\hat{p}_p*n_2>10$
        -   $.7*180>10$
    -   $(1-\hat{p}_p)*n_2>10$
        -   $.3*180>10$

#### CI

![](Images\CI_prop.png)

$$
\sqrt{\frac{.8*.2}{200}+\frac{.7*.3}{180}}=0.00443
$$

![](Images\lab_plot.png)

-   $.1+.00433*1.96=0.109$
-   $.1-.00443*1.96=0.091$

We are 95% confident that the true proportion of patients who took the
new drug and recovered is 0.091 to 0.109 HIGHER than the true proportion
of patients who took the placebo and recovered.

### Relationship Between Z-test and CI

When working with a two-tailed test, if you reject the null hypothesis
at $\alpha=0.05$ level, we would expect our 95% CI to not include the
null values.

The condition for rejecting the null hypothesis is that the absolute
Z-statistic is greater than the critical value,

$$
|Z_{stat}|>Z_{crit}
$$

Which can be rearranged to show,

$$
|\hat{p}-p_0|>Z_{crit}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}
$$

For **quantitative variables**, the key insight is that when you reject
the null hypothesis, the distance between your statistic and the null
value is larger than the margin of error of the confidence interval.
Since the null value is a certain distance away from your sample
proportion, and that distance is greater than the width of your
confidence interval, the null value cannot possibly be inside the
interval.

# Week 7

## Central Limit Theorem

![](Images\cltmean.png)

![](Images\cltmean_2.png)

## t-Distribution

Similar to normal distribution, but has more uncertainty.

-   There are infinite t-distributions vs. the singular normal
    distribution

-   t-distribution approach a normal distribution as you increase your
    degrees of freedom.

-   Used when the population standard deviation is unknown.

-   Used for quantitative data.

### Degrees of Freedom

DF for a t-distribution refer to the number of independent pieces of
information that available to estimate a parameter. In the context of
the t-distribution, DF are a parameter that determines the shape of the
distribution.

-   $DF = n-1$

DF correct for the uncertainty introduced when estimating the population
standard deviation using the sample deviation when working with a
quantitative variable.

Since the standard error of the sampling distribution is known for
hypothesis test with categorical data, derived from $\pi_o$ , we don't
correct with t, instead we use the standard normal distribution.

### Connecting the dots

If the hypothesis test leads you to reject the null hypothesis, it means
that the distance between $\bar{x}$ and $u_o$ is greater than the margin
of error defined by the 95% CI.

![](Images\t_test.png)

### Mathematical Proof

$$
|\frac{\bar{x}_1-u_o}{SE}|>t^*
$$

$$
|\bar{x}_1-u_o|>t^**SE
$$

This inequality states that the distance from the center of the interval
to the null value $μ_o$ is greater than the margin of error. If the
distance to $μ_o$ is longer than the margin of error around the sample
mean, the confidence interval must exclude $μ_o$.

These two equations are mathematically equivalent, proving that
rejecting $H_o$ is the same as the confidence interval excluding the
null value $u_o$.

-   For a two-side test where $\alpha$ "matches" with our confidence
    interval you would get something like, $\alpha=0.05$ and a 95% CI.

With categorical data the difference in their numerical values is
usually too small to break the equivalence.

# Week 7

## T-Test Math Notation

![](Images\ttest_equ.jpg)

### Standard Deviation

![](Images\sd_formula.webp)

### Between Groups

![](Images\tdiff_test.png)

### Confidence Interval

Need to know the margin of error, which you should $\pm$ from your best
guess.

![](Images\ME_t_test.png)

# Week 9-10

## ANOVA

ANOVA is an extension from difference in means, where the test statistic
is the variability (variance) within group vs the variability (variance)
across groups.

#### Hypothesis Notation:

Example text comes from the plants dataset in R.

$$
H_o: \mu_c = \mu_{trt1} = \mu_{trt2}
$$

**In words:**

-   $H_o:$ The population mean weight of plants across the three groups
    are equal.

-   $H_a:$ At least one population mean plant weight is different across
    the three groups.

Note: It is uncommon to write our the alternative hypothesis in
notation, but the null is generally written in proper notation.

#### Assumptions

**Independence**

-   Between groups

-   Across groups

**Normality**

-   Check using quantiles and a Normal q-q plot to determine if the data
    is normally distributed.

    -   We plot the values from our data set against what woe would
        expect the values to look like if they were normally distributed

    -   If the dots roughly follow a straight line, we have evidence of
        normality.

![](\Images\normal_qq.png)

![](\Images\right_qq.png)

**Equal variance**

General rule: Is the largest sample standard deviation more than twice
the smallest sample standard deviation?

#### The Math Behind ANOVA

$$
F = \frac{MS_{Between}}{MS_{Within}} \\
F = \frac{\frac{SS_{Between}}{k-1}}{\frac{SS_{Within}}{N-k}} \\
SS_{Between} = \sum^k_{i=1}n_i(\bar{X}_i-\bar{X}_{grand})^2 \\
SS_{Within} = \sum^k_{i=1}\sum^{n_i}_{j=1}(X_{ij}-\bar{X}_i)^2
$$

-   SS means sum of squares

-   F is our statistics

##### Definitions

The Sum of Squares (SS) is a measure of total variability (between or
within)

The Mean Squares (MS) is an estimate ($s^2$) of the population variance
($\sigma^2$), represented as,

$$
s^2=\frac{\sum(x_i-\bar{x})^2}{n-1}
$$

-   This is the $\frac{SS}{df}$

#### F Distribution

A continuous, positively skewed probability distribution, characterized
by two degrees of freedom (numerator and denominator) that determine its
shape.

-   Always one tail no matter what

##### Degrees of Freedom

Degrees of Freedom (df) is the number of independent pieces of
information used to calculate the statistic

When we estimate the population (grand) mean, there are $k-1$
independent pieces of information

When we estimate the population means within each group, there are
$n - k$ independent pieces of information

##### F-Statistic

The whole goal of Anova is to compare the variability between groups vs
the variability within groups.

### Tukeys HSD

The main idea of the hsd is to compute the honestly significant
difference (hsd) between all pairwise comparisons

#### Type 1 Error

$\alpha$ is our significance level, and our Type I error rate.

-   A **Type I error** is the risk rejecting the null hypothesis when
    the null hypothesis is actually true.
    -   As an example when $\alpha=0.05$ that means you have a 5% risk
        of rejecting the null hypothesis when it is actually true.

#### Family-Wise Error Rate

Family-wise error rate (FWER) is the probability/risk of making one or
more Type I error across all tests in a family of comparisons. It is a
way to quantify the risk of making Type I errors during multiple
hypothesis testing.

The formula is,

$$
FWER = 1 - (1-\alpha)^m
$$

Where $m$ is the number of comparisons.

$$
\text{k choose 2} = \frac{k(k-1)}{2}
$$

#### Pairwise Comparisons

Commonly we report confidence intervals to estimate which means are
actually different (also reports p-values)

Tukey's HSD can be represented as,

$$
\bar{x}_1-\bar{x}_2 \pm q^**\sqrt{MSE*\frac{1}{n_j}+\frac{1}{n_{j}^*}}
$$

Where:

-   $q^*$ is a value from the studentized range distribution

-   (MSE) refers to the average of the squared differences between
    individual data points within each group and their respective group
    mean, divided by the degrees of freedom. Also know as the estimated
    variance by pooling all the groups.

$$
MSE = \sum^k_{i=1}\frac{(n_i-1)s^2_i}{N-k}
$$

##### How to find $q^*$

Can be found using the `qtukey()` function

```{r}
qtukey(p = 0.95, nmeans = 3, df = 27)
```

#### Test-statistic

$$
Q = \frac{\bar{x}_i-\bar{x}_j}{\sqrt{\frac{MSE}{2}(\frac{1}{n_i}+\frac{1}{n_j})}}
$$

#### Summary

Tukey’s Honest Significant Difference (HSD) test is a post hoc test
commonly used to assess the significance of differences between pairs of
group means. Tukey HSD is often a follow up to one-way ANOVA, when the
F-test has revealed the existence of a significant difference between
some of the tested groups.

### Bonferroni

Tukey's HSD is best for making all possible pairwise comparisons, while
**Bonferroni Correction** is more general and suited for a small number
of pre-planned comparisons.

You conduct individual t-tests, but divide by the original significance
level $\alpha$ by the number of tests being performed ($m$)

# Week 11

## Chi-Square Test

The big idea is to compare expected counts (the assumed counts under the
null hypothesis) with the observed counts (your results). This is used
to calculate the test statistic.

#### Hypothesis Notation

Ho: Sex and species of penguins are independent

Ha: sex and species of penguins are not independent

Remember for the null this means species has no impact **OR** species is
completely independent from sex. While for the alternative this means
species has some impact on sex **OR** species is not independent from
sex.

##### Assumptions

-   Independence

![](Images\chi_ind.png)

-   Expected Frequencies

    -   Expected cell count should be \> 5
    -   If any of the expected values are low, the p-values generated by
        the test start to lose reliability. Should check this in our
        table.

#### Chi-Square Distribution

Binomial Approximation: The observed Counts in a contingency table
follow a binomial distribution

The Central limit theorem tells us that when the number of trials ($n$)
is large enough, the binomial distribution can be reasonably
approximated by the normal distribution

The Chi-Square test relies on the assumption that the sampling
distribution of the observed frequencies (counts) is close enough to a
normal distribution for the $X^2$ statistic to accurately follow the
theoretical Chi-Square distribution

When Expected Counts are high ($\geq5$): The underlying discrete
(integer) count data behaves smoothly, like a continuous bell-shapped
(Normal) curve

When Expected Counts are low ($<5$): The data distribution remains
highly skewed and chunky (discrete). It looks nothing like the smooth
Normal distribution.

If our sample size assumption (expected counts) is not met, the test
statistic doesn’t actually follow the distribution it’s being compared
to…. so we can’t trust the results.

#### Expected Counts

To calculate the expected count for the $i^{th}$ row and $j^{th}$
column,

$$
\text{Expected Count}_{\text{row i, col j}} = \frac{\text{(row i total)}*\text{(col j total)}}{\text{table total}}
$$

![](Images\expected_counts.png)

![](Images\expected2.png)

#### Test Statistic

![](\Images\chisq.png)

-   $r$ is the number of groups for one variable (rows)

-   $c$ is the number of groups for the second variable (columns)

-   The test statistic cannot be negative

##### p-value

To calculate the p-value you can use `chisq_test(data, var1 ~ var2)`

##### Notation

The probability of observing our statistic, or something larger given
the null hypothesis is true.

-   $P(\chi^2 \geq X^2) = \text{p-value}$

    -   $\chi^2$ = map of possible outcomes on the chi-square
        distribution (random variable because it is generated from a
        random process)

    -   $X^2$ = your statistic

#### Important Notes

-   The shape of the Chi-Square distribution curve depends on the
    degrees of freedom

-   The chi-square distribution is skewed to the right, and the
    chi-square test is always right-tailed

-   A chi-square test cannot have a directional hypothesis. A chi-square
    value can only indicate that a relationship exists between two
    variables, not what the relationship is.

#### Chi-Square Difference in Proportions

![](Images\chi_dp.png)

![](Images\show_it.png)

**Z-Statistic**

$$
Z = \frac{(\hat{p}_1-\hat{p}_2)}{SE_{pooled}} = \frac{(0.5385 -0.3684)}{0.1786} = \frac{0.1701}{0.1786} \approx 0.952 
$$

$$
.952^2 = .906
$$

```{r}
counts_table <- matrix(c(7,7,6,12), nrow = 2)

prop.test(counts_table, correct = F)
```

# Week 12-13

## Linear Regression

#### Summary Statistics

Correlation (r):

-   Is bounded between \[-1, 1\]

-   Measures the strength + direction of a linear relationship

-   The correlation value has no units and is not impacted by a linear
    change in units (e.g. going from inches to centimeters)

![](Images\r_corr.webp)

Slope + intercept (fit a line)

#### Syntax

`cor(x, y)`

```{r}
library(tidyverse)

airquality |>
  summarise(corr = cor(Wind, Temp, use = "complete.obs"))
```

```{r}
airquality |>
  ggplot(aes(x = Wind, y = Temp)) +
  geom_point() +
  geom_smooth(method = 'lm', se = F, formula = 'y ~ x')
```

#### Residual

The residual of the $i^{th}$ observation $(x_i,y_i)$ is the difference
of the observed outcome and the outcome we would predict based on the
model fit:

$$e_i = y_i-\hat{y}_i$$

-   $y_i$ is an observed value.

-   $\hat{y}_i$ is the predicted value based on the line. It is
    typically found by plugging $x_i$ into the model.

To minimize the residual sum of squares:

$$
\sum(y_i-\hat{y})^2
$$

##### Residual Overlay Plot:

```{r}
# Fitting a linear model
air_lm <- lm(Wind ~ Temp, data = airquality) 

# Adding fitted and residuals 
airquality$fit  <- fitted(air_lm)
airquality$res  <- resid(air_lm)

# Creating residual overlay plot
ggplot(airquality, aes(Temp, Wind)) +
  geom_segment(aes(xend = Temp, yend = fit), alpha = 0.6) + 
  geom_point() +
  geom_smooth(method = "lm", se = F, formula = y ~ x, color = "purple") +
  labs(title = "Residuals", y = "Wind", x = "Temp")

```

#### Linear Regression Equation

Population level: $y=\beta_0+\beta_1*x+\epsilon$

Sample: $\hat{y}=\hat{\beta_0}+\hat{\beta_1}*x$

-   $\hat{y}$ (yhat) = predicted value of y

-   $\hat{\beta_0}$ (b) = estimated intercept

-   $\hat{\beta_1}$ (b1) = estimated slope

-   $x$ = explanatory variable

The slope describes the estimated difference in the predicted average
outcome of $y$ if the predictor variable $x$ happened to be one unit
larger. The intercept describes the average outcome of $y$ if $x$ = 0
and the linear model is valid all the way to $x$ = 0 (values of $x$ = 0
are not observed or relevant in many applications)

![](Images\lsq_line.png)

##### Categorical Predictors

The estimated intercept is the value of the outcome variable for the
first category (i.e., the category corresponding to an indicator value
of 0). The estimated slope is the average change in the outcome variable
between the two categories.

##### Coefficient of Determination

$R^2$ is also called the coefficient of determination, which is the
proportion of variability in the outcome variable explained by the
model.

Since $r$ is always between -1 and 1, $R^2$ will always be between 0
and 1. It measures the proportion of variation in the outcome variable,
$y$, that can be explained by the linear model with predictor $x$.

##### Sums of Squares

![](Images\sumofsquares.png)

#### R-Code

```{r, echo=FALSE}
library(tidymodels)
air_model <- lm(Wind ~ Temp, data = airquality)

tidy(air_model)
```

#### Why Mean Response

The phrase expected value is a synonym for mean value in the long run
(meaning for meany repeats or a large sample size)

![](Images\slr_image.png)

#### Null and Alternative Hypothesis

$H_o:\beta_1=0$

$H_a:\beta_1\neq0$

#### Assumptions

##### Independence

Most important thing is how you sample the data, with the fundamental
idea being that the population you randomly sampled from had an equal
chance for selection, and that the observations are independent from one
another.

To check you will want to plot the residuals:

```{r}
plot(airquality$Temp, airquality$res,
     ylab = "Residuals",
     xlab = "Temperature",
     main = "Wind Speed Residuals"
     )
abline(0, 0)
```

The residuals should be randomly and symmetrically distributed around
zero under all conditions, and in particular there should be no
correlation between consecutive errors no matter how the rows are
sorted, as long as it is on some criterion that does not involve the
dependent variable. If this is not true, it could be due to a violation
of the linearity assumption or due to bias that is explainable by
omitted variables (say, interaction terms or dummies for identifiable
conditions). [Source](https://people.duke.edu/~rnau/testing.htm)

##### Linearity

The first step is to look at a scatter plot of the data, to see if there
is a clear violation of linearity. If you don't notice a clear
polynomial or logistic regression, that is a good sign of a linear
relationship.

Non-linearity is most evident in a plot of **residual vs. fitted
(predicted) values**. The points should be symmetrically distributed
around a horizontal line, with a roughly constant variance. The points
should appear random rather than following a specific pattern. What you
are checking for is equal variance.

![](Images\res_fitted.png)

A violation of linearity would appear to show a clear bowed pattern:

![](Images\violation.png)

##### Equal Variance

Violations of homoscedasticity (which are called "heteroscedasticity")
make it difficult to gauge the true standard deviation of the forecast
errors, usually resulting in confidence intervals that are too wide or
too narrow, and creates inaccurate p-values. Heteroscedasticity may also
have the effect of giving too much weight to a small subset of the data
(namely the subset where the error variance was largest) when estimating
coefficients.

You do not want to see the residual plot showing unequal spread of data,
if there is a clear pattern as in the plot below, that is a good sign
the data does not have equal variance.

![](Images\homosce.png)

##### Linearity and Equal Variance Summary

![](Images\resvfit.png)

##### Normality

We think about our sample size and also look at Normal Q-Q plots of our
residuals. The residuals should roughly follow the straight line mapped
by the plot, deviations would indicate the data may not meet the
normality assumption. If the sample size is large the CLT would account
for minor deviations, but if your sample size is small minor deviations
should be carefully evaluated.

```{r}
airquality |>
  ggplot(aes(sample=res)) +
  stat_qq() +
  stat_qq_line(color = "red") +
  labs(
    title = "Normal Q-Q Plot of Residuals",
    subtitle = "Model: Wind ~ Temp (Airquality Data",
    x = "Theoretical Quantiles (Standard Normal)",
    y = "Sample Quantiles (Residuals)"
  )
  
```

A faster way to make plots for your linear regression is to just use the
built in `plot()` function on your model:

```{r}
plot(air_lm)
```

#### Test Statistic

$$
t = \frac{\hat{\beta_1}-\beta_{null}}{SE(\hat{\beta_1})}
$$

##### Standard Error

![](Images\se_lin.png)

#### Confidence Intervals and Predictions

How to predict true mean Wind (mph) when the Temp is 17 degrees? Note
that a Temp of 17 is outside the bounds of our data, meaning we are
extrapolating.

##### Response

$$
\hat{\mu_y} \pm t^**SE_{\hat{\mu_y}}
$$

##### Standard Errors

$X_{given}$ = What we set X equal to

![](Images\xgiven.png)

The term $\frac{1}{n}$ accounts for the general uncertainty in
estimating the intercept.

The term $\hat{\sigma}^2$ in the outer square root represents the
uncertainty around our prediction.

The uncertainty introduced by the slope ($\hat{\beta}_1$) is accounted
for by,

$$
\frac{(X_{given}-\bar{X})^2}{\sum^n_{i=1}(X_i-\bar{X})^2}
$$

##### R-Code

```{r}
model1 <- lm(Wind ~ Temp, data = airquality)

new_temp_data <- tibble(Temp = 17)

predict(
  model1, 
  newdata = new_temp_data, 
  interval = "confidence", 
  level = 0.95
)
```

## Multiple Linear Regression

-   Has a quantitative response (Y)

-   Has \> 1 explanatory variable

-   The values of the coefficients change when we add more variables
    into our model

### Additive Model

The relationship between x and y does not depend on z

```{r}
library(palmerpenguins)

penguins_clean <- penguins |>
  filter(bill_length_mm != is.na(bill_length_mm),
         flipper_length_mm != is.na(flipper_length_mm))

# Creating additive model
add_model <- lm(flipper_length_mm ~ bill_length_mm + species, data = penguins_clean)

# Grabbing predictions
penguins_clean$pred_flipper <- predict(add_model)

# Creating new data to assign full x scale to
x_scale_df <- expand.grid(
  bill_length_mm = seq(
    from = min(penguins_clean$bill_length_mm),
    to = max(penguins_clean$bill_length_mm),
    by = .1, # Sets the scale increments
  ),
  species = unique(penguins_clean$species)
)
                            
                          

# adding new prediction lines
x_scale_df$predline <- predict(add_model, x_scale_df)

ggplot(data = penguins_clean, aes(x = bill_length_mm, y = flipper_length_mm, color = species)) +
  geom_point(alpha = 0.5) +
  geom_line(data = x_scale_df, aes(y = predline), size = 1) +
  labs(
    title = "Additive Model",
    subtitle = "Model: Flipper Length ~ Bill Length + Species (Same Slope, Different Intercepts)",
    x = "Bill Length (mm)",
    y = "Flipper Length (mm)"
  ) +
  theme_minimal()
```

##### Model Output

```{r}
tidy(add_model)
```

#### General Formula

$$
\hat{Y} = \hat{\beta_0} + \hat{\beta}_1X_1 + \hat{\beta}_2X_2 + \text{...} + + \hat{\beta}_kX_k
$$

Our formula in our example would be,

$$
\hat{fl} = 147.951 + 1.083 * \text{bl} - 5.004 * \text{chin} + 17.799 * \text{gentoo}
$$

$$
I_{Gentoo} \{\text{1 when Gentoo, 0 for all else}
$$

$$
I_{Chin} \{\text{1 when Chin, 0 for all else}
$$

-   147.95 represents the intercept for Adelie penguins which is our
    baseline reference, the formula just looking at the Adelie penguins
    would look like,

$$
\hat{fl}_{Adelie} = 147.951 + 1.083 * \text{bill}
$$

-   To represent just the formula for Chinstrap penguins we could use,

$$
\hat{fl}_{Chin} = 147.951  - 5.004 + 1.083 * \text{bill}
$$

#### Interpretations

Holding species constant, for a 1mm increase in bill length, we estimate
an average increase in flipper length of 1.083mm.

Holding bill length constant, we estimate the mean flipper length of
Gentoo penguins to be 17.799mm larger than the Adelie penguins.

### Interaction Model

The relationship between x and y depends on the value of z.

```{r}
inter_model <- lm(flipper_length_mm ~ bill_length_mm * species, data = penguins_clean)

penguins_clean |>
  ggplot(
    aes(x = bill_length_mm, y = flipper_length_mm, color = species)
  ) + 
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = F, formula = "y ~ x") +
  labs(
    title = "Interaction Model",
    subtitle = "Flipper Length ~ Bill Length * Species (Non-Parallel Slopes)",
    x = "Bill Length (mm)",
    y = "Flipper Length (mm)"
  ) +
  theme_minimal()
```

#### Output

```{r}
tidy(inter_model)
```

How would we interpret something like the 0.207 value?

For a 1mm increase in bill length, we estimate an average increase in
flipper length of 0.207mm more for Chinstrap than Adelie penguins,
holding all other variables constant.

#### Formula

$$
\hat{Y} = \hat{\beta_0} + \hat{\beta}_1X_1 + \hat{\beta}_2X_2 + \hat{\beta}_3(X_1X_2)
$$

For our example the formula would look like,

$$
\hat{fl} = 158.92  + 0.80 *bill - 12.29 * Chin - 7.83 * Gentoo + .207 * bill * Chin + .591 * bill * Gen 
$$

The line for just Adelie penguins would look like,

$$
\hat{fl}_{Adelie} = 159 + .800 * bill
$$

The line for just Chinstrap penguins would look like,

$$
\hat{fl}_{Chin} = 159 - 12.29 + .800 * bill + .207 * bill
$$ - $159 - 12.29$ is the change to our intercept in the model while
$bill(.800 + .207)$ would represent our slope

#### Assumptions

We use the same assumptions as the assumptions we used for singular
linear regression models, but add another assumption for
multicollinearity.

Multicollinearity happens when the predictor variables are correlated
within themselves. When the predictor variables themselves are
correlated, the coefficients in a multiple regression model can be
difficult to interpret.

##### Multicollinearity Example

This is an example using fake data:

![](Images\multi.png)

![](Images\multi1.png)

The photos show how the variables react in a linear regression model on
their own.

![](Images\multi3.png)

TO check this assumption you can calculate correlation coefficients
between all your predictors. You can also calculate variance inflation
factors (not covered in course)

### Hypothesis Test for Multiple Linear Regression

To illustrate this lets first look back at our examples for our simple
linear regression compared to our additive multiple linear regression.
Represented by the formulas,

$$
fl = \beta_0 + \beta_1 * bill + \epsilon
$$

$$
fl = \beta_0 + \beta_1 * bill + \beta_2 * Chin + \beta_3  * Gentoo + \epsilon
$$

The question is to try and determine if the multiple linear regression
model is worth it. One thing to remember is that you are never going to
get worse at predicting your response variable by adding extra terms,
you are merely checking if adding those extra terms are worth it.

#### Notation

$H_0: \beta_2 = \beta_3 = 0$

$H_a: \text{At least one of the betas differ from zero}$

The idea is to see if the reduction in unexplained variance (the
reduction in Residual Sum of Squares, RSS) when moving from
$Model_{reduced}$ to $Model_{full}$ is statistically significant. In
other words, is species a good predictor to include in our analysis.

#### Test Statistic

$$
F = \frac{(RSS_R-RSS_f)/(df_R-df_F)}{MSE_F}
$$

$df_F = n - k_F -1$: n is our sample size, while k is the number of
predictors

$df_R = n - k_R -1$: n is our sample size, while k is the number of
predictors

-   F represents our full model, while R represents our reduced model.

##### Visualization

We are comparing the Residual Sum of Squares between the two models

Reduced Model:

```{r}
# Fitting a linear model
peng_slm <- lm(flipper_length_mm ~ bill_length_mm, data = penguins_clean) 

# Creating clone df
peng_clone <- penguins_clean

# Adding fitted and residuals 
peng_clone$fit  <- fitted(peng_slm)
peng_clone$res  <- resid(peng_slm)

# Creating residual overlay plot
ggplot(peng_clone, aes(x = bill_length_mm, y = flipper_length_mm)) +
  geom_segment(
    aes(xend = bill_length_mm, yend = fit), 
    color = 'black',
    linetype = 'dotted',
    alpha = 0.5
  ) + 
  geom_smooth(method = "lm", se = F, formula = y ~ x, color = "purple") +
  geom_point(color = 'darkorange', alpha = 0.6) +
  labs(
    title = "Residual Distances for the Reduced Model", 
    subtitle = "Model: Flipper Length ~ Bill Length. Vertical lines show model error (residuals)",
    x = "Bill Length (mm)", 
    y = "Flipper Length (mm)"
  ) +
  theme_minimal()
```

Full Model:

```{r}
# Fitting a linear model
peng_flm <- lm(flipper_length_mm ~ bill_length_mm + species, data = penguins_clean) 

# Creating clone df
peng_clone1 <- penguins_clean

# Adding fitted observations to df
peng_clone1$fit  <- fitted(peng_flm)

# Creating residual overlay plot
ggplot(peng_clone1, aes(x = bill_length_mm, y = flipper_length_mm, color = species)) +
  geom_segment( 
    aes(xend = bill_length_mm, yend = fit), # draws a line from observed points to fitted value
    color = "black",
    linetype = 'dotted',
    alpha = 0.5
  ) +
  geom_point(alpha = 0.6) +
  geom_line(aes(y = fit), size = 1) + # y = fit is the values created from the linear model
  labs(
    title = "Residual Distances for the Full Additive Model (Forced Parallel Lines)", 
    subtitle = "Model: Flipper Length ~ Bill Length + Species",
    x = "Bill Length (mm)", 
    y = "Flipper Length (mm)"
  ) +
  theme_minimal()
```

You can compare the length of the distance between residuals and how
that compares between a singular line versus multiple lines.

#### Assumptions

You need to check for both models:

-   Independence

    -   Same as with simple linear regression you just want to make sure
        it is reasonable your data is independent. You will want a
        simple random sample

-   Linearity

-   Normality of Residuals

-   Equal Variance

-   Nested models

##### Linearity and Equal Variance

```{r}
# Adding residuals to df
peng_clone1$res <- resid(peng_flm) 

# residual plot vs fitted
ggplot(data = peng_clone1, aes(x = fit, y = res)) +
  geom_point(alpha = 0.6) +
  geom_hline(
    yintercept = 0,
    color = 'red',
    linetype = 'dashed',
    size = 1
  ) +
  geom_smooth(
    method = 'loess',
    se = F,
    color = 'blue',
    size = 1
  ) +
  labs(
    title = "Residuals vs Fitted Plot",
    subtitle = "Model: Flipper Length ~ Species + Bill Length",
    x = "Fitted Values (Predicted Flipper Length)",
    y = "Residuals (Error)"
  ) +
  theme_minimal()
  
```

Based on this plot we can see that the residuals are fairly randomly
distributed around zero indicating the data meets the linearity
assumption. For equal variance we want to see the data is spread across
the plot without creating an imbalance between any specific part along
the x-axis. Since the residuals are not fanning out or funneling into to
any specific point, we can state the model meets the assumption of equal
variance.

##### Normality

```{r}
peng_clone1 |>
  ggplot(aes(sample = res)) +
  stat_qq(color = 'darkgreen') +
  stat_qq_line(color = 'black', size = 1) +
  labs(
    title = "Normal Q-Q Plot of Residuals for Flipper Length Model",
    subtitle = "Model: Flipper Length ~ Species + Bill Length",
    x = "Theoretical Quantiles (Normal Distribution)",
    y = "Sample Quantiles (Model Residuals)"
  ) +
  theme_minimal()
```

Since we have a large sample size we are more robust to deviations of
normality, so we can be robust to the outlier seen on the left tail of
our plot.

```{r}
plot(peng_flm)
```

##### Nested Models

Your reduced model has to be inside your full model, otherwise it will
create negative values that will impact the ability to calculate your
test statistic.

#### R-Code for Anova for Comparisons

```{r}
model_reduced <- lm(flipper_length_mm ~ bill_length_mm, data = penguins)

model_full <- lm(flipper_length_mm ~ bill_length_mm + species, data = penguins)

anova(model_reduced, model_full)
```

The DF column difference in residual degrees of freedom between the two
adjacent models being compared. This is the numerator degrees of freedom
for the F-test. The denominator degrees of freedom is the Residual
degrees of freedom from the full model (338).

The 26923 is the reduction in the Residual Sum of Squares (RSS) from the
reduced to full model.

Our p-value comes from a F-distribution with 2 and 338 degrees of
freedom.

##### Interpretation

Since our p-value is really small we can reject the null hypothesis, and
state that the amount of variation in flipper length explained by the
addition of species is statistically significant.

#### Additive vs Interaction Model

Additive:

$$
fl = \beta_0 + \beta_1 * bill + \beta_2 * Chin + \beta_3  * Gentoo + \epsilon
$$

Interaction:

$$
fl = \beta_0 + \beta_1 * bill + \beta_2 * Chin + \beta_3  * Gentoo + \beta_4*bill*Chin + \beta_5 * bill * Gentoo + \epsilon
$$

Since we previously plotted our residuals for our additive model lets
see what it would look like on our interaction model

```{r}
# Fitting a linear model
peng_flm <- lm(flipper_length_mm ~ bill_length_mm * species, data = penguins_clean) 

# Creating clone df
peng_clone1 <- penguins_clean

# Adding fitted observations to df
peng_clone1$fit  <- fitted(peng_flm)

# Creating residual overlay plot
ggplot(peng_clone1, aes(x = bill_length_mm, y = flipper_length_mm, color = species)) +
  geom_segment( 
    aes(xend = bill_length_mm, yend = fit), # draws a line from observed points to fitted value
    color = "black",
    linetype = 'dotted',
    alpha = 0.5
  ) +
  geom_point(alpha = 0.6) +
  geom_line(aes(y = fit), size = 1) + # y = fit is the values created from the linear model
  labs(
    title = "Residuals for the Full Interaction Model", 
    subtitle = "Fitted Lines: Flipper Length ~ Bill Length * Species (Different Slopes and Intercepts",
    x = "Bill Length (mm)", 
    y = "Flipper Length (mm)"
  ) +
  theme_minimal()
```

##### Anova Comparison

```{r}
model_additive <- lm(flipper_length_mm ~ bill_length_mm + species, data = penguins_clean)

model_interaction <- lm(flipper_length_mm ~ bill_length_mm * species, data = penguins_clean)

anova(model_additive, model_interaction)
```

##### Hypothesis Notation

$H_0: \beta_4 = \beta_5 = 0$

$H_A:$ At least one of $\beta_4 \ \text{or} \ \beta_5 \ne 0$

At a significance level of $\alpha = 0.05$ and a p-value of 0.0523 we
fail to reject the null hypothesis. Due to the closeness to the $\alpha$
level we can state there is weak evidence that the addition of
interaction effect between bill length and species better explains the
variation in flipper length over our Additive model.

# Week 14-15

## Statistical Inference vs Sampling Variability

Statistical Inference - taking a sample, and making claims about a
larger population.

Sampling Variability - the natural variability (error) we expect/see
from sample to sample.

-   Ex: Let’s assume that Gen-Z has a mean credit score of 680 (μ=680).
    If you take a random sample of 100 Gen-Z individuals, would we
    expect the mean credit score of those 100 to be exactly 680?

    -   No, we would not assume it be the exact same mean. Because we
        know this, we account for sampling variability by using
        distributions (instead of just point estimates) when trying to
        make claims about an entire population (Stastical Inference)!

### Scenarios

It’s important for us to know when methods are vs are not appropriate,
based on variable type. We are going to go through three examples and
identify each scenario on which methods would be most appropriate to
answer the research question.

#### Example 1

An ecologist is studying a population of small mammals (e.g., field
mice) to see if their primary habitat is associated with their dominant
predator avoidance tactic. The study aims to determine if animals that
live in dense forest prefer to hide, while those in open fields prefer
to flee.

![](Images\ex1.png)

-   This would use a Chi-Square Distribution, thus statistical inference
    is used.

#### Example 2

What was the median student loan debt for all 350 students who graduated
from the Engineering School in May 2025?

-   This would not need any form of statistical inference as your
    population of interest would be all 350 students, thus sampling
    variability does not need to be accounted for.

#### Example 3

A pharmacologist is studying the factors that influence patient Recovery
Time (in days) following a specific surgical procedure. They are
analyzing the effects of a new post-operative drug and the patient’s
age.

The researcher hypothesizes a significant interaction between the two
factors: the new drug may be highly effective (significantly reducing
recovery time) for younger patients, but its efficacy might be greatly
reduced or even disappear for older patients due to metabolic changes.

-   Since this would be looking at a categorical explanatory variable
    (new drug or no new drug) with an interaction effect using a
    quantitative explanatory variable (age of patient) analyze a
    quantitative response variable (recovery time) the best option would
    be to conduct statistical inference using regression.

## Logistic Regression

Logistic regression is a modeling tool used for a categorical response
variable. Is very similar to linear regression, but obviously the
response variable is different.

### The Problem

$(\mu_y) = (\beta_0 + \beta_1X_1 + ...)$

-   The right side of a regression equation, which cant take any value
    from $-\infty$ to $\infty$.

$(\mu)$: The expected value of the response variable, which is
restricted to a certain range (e.g. a probability must be between 0 and
1).

Applying a specific mathematical transformation to the expected outcome
(or mean) of your model in order to linearly relate it to your predictor
variables, while restricting the values of your response variable
accordingly.

For logistic regression, this is the logit-link function:

$(\mu_y \ or \ p)$

$ln(\frac{p}{1-p})$ = log - odds

-   $p$ = probability of success

-   $1-p$ = probability of failure

-   odds = $\frac{p}{1-p}$

$\widehat{ln(\frac{p}{1-p})} = \hat{\beta}_0 +\hat{\beta}_1X_1+...$

### Generalized Linear Model (GLM)

GLM is another term for a type of logistic regression model. Where we
want to fit an S curve and model the probablity of success as a function
of explanatory variable(s).

![](Images/log_curve.png)

#### Terms

Bernoulli Distribution:

-   2 outcomes: Success (p) or Failure (1-p)

-   $y_i$ \~ Bern(p)

-   We use $p_i$ for estimated probabilities

#### The model

$$
\widehat{ln(\frac{p}{1-p})} = \hat{\beta_o} + \hat{\beta_1}X_1 + ...
$$

-   $ln(\frac{p}{1-p})$ is called the logit link function, and can take
    on values from $-\infty$ to $\infty$

-   $ln(\frac{p}{1-p})$ represents the log odds of a success

##### Log Odds

$ln(\frac{p}{1-p})$ = natural logarithm of the odds, where the odds are
the ratio of the probability of an event happening to the probability of
it not happening.

$ln(\frac{p}{1-p})$ has good modeling properties (ex. unbounded; handles
extreme values of p well for linearity; restricts p to be between 0 and
1), but it is hard to interpret. Think of this as our initial model,
that we will work with to model probabilities (can also model odds).

-   $p$ stands for probability

-   The logit link function restricts p to be between the values \[0,
    1\]

#### Math

We want to model probabilities. We want to isolate $p$ on the left side
of the equation,

$$
\widehat{ln(\frac{p}{1-p})} = \hat{\beta_o} + \hat{\beta_1}X_1 + ...
$$

To isolate the $p$ we get rid of the $ln$ by,

$$
e^{ln(\frac{p}{1-p})} = e^{\beta_0+\beta_1X1}
$$

$$
\frac{p}{1-p} = e^{\beta_0+\beta_1X1}
$$

Times each side by $(1-p)$,

$$
p = e^{\beta_0+\beta_1X1} * (1-p)
$$

$$
p = e^{\beta_0+\beta_1X1} - pe^{\beta_0+\beta_1X1}
$$

Add the new $p*e$ term to the other side,

$$
p +pe^{\beta_0+\beta_1X1} = e^{\beta_0+\beta_1X1}
$$

Simplify the equation to just one p,

$$
p(1+e^{\beta_0+\beta_1X1}) = e^{\beta_0+\beta_1X1}
$$

Divide both side by the $(1+e)$ term,

$$
p = \frac{e^{\beta_0+\beta_1X1}}{1+e^{\beta_0+\beta_1X1}} \ \text{where} \ p = [0,1]
$$

##### Final Model

$$
\hat{p} = \frac{e^{\hat{\beta_0}+\hat{\beta_1}X1}}{1+e^{\hat{\beta_0}+\hat{\beta_1}X1}} \ \text{where} \ p = [0,1]
$$

#### Recap

With a categorical response variable, we use the logit link (logistic
function) to calculate the log odds of a success,

$$
\widehat{ln(\frac{p}{1-p})} = \hat{\beta_o} + \hat{\beta_1}X_1 + ...
$$

We can use the same model to estimate the probability of a success,

$$
\hat{p} = \frac{e^{\hat{\beta_0}+\hat{\beta_1}X1}}{1+e^{\hat{\beta_0}+\hat{\beta_1}X1}} \ \text{where} \ p = [0,1]
$$

![](Images/pred_probs.png)

#### Prediction Interval

$$
\hat{p} \pm ME
$$

$ME = t^* * SE(\hat{p})$
